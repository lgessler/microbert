<html><body><text id="wikipedia_id_wikipedia_org__7.html" ns="0" revid="19247574" sourceurl="https://id.wikipedia.org/wiki/Analisis_leksikal" title="Analisis leksikal" type="wikipedia">Analisis leksikal<p><hi rend="bold">Analisis leksikal</hi> (bahasa Inggris: <hi rend="italic">lexical analysis</hi>) adalah sebuah proses yang mendahului <ref target="https://id.wikipedia.org/wiki/Parsing">parsing</ref> sebuah rangkaian karakter. Ia menerima masukan serangkaian karakter (seperti dalam dokumen plain-text atau source code) dan menghasilkan deretan simbol yang masing-masing dinamakan <hi rend="bold">token</hi>; proses parsing akan lebih mudah dilakukan bila inputnya sudah berupa token.</p>
<p>Analisis leksikal terdiri dari dua tahap. Tahap pertama adalah <hi rend="bold">pemindaian</hi> (<hi rend="italic"><hi rend="bold">scanning</hi></hi>); scanner biasanya dibuat berdasarkan prinsip Finite State Machine ("mesin dengan jumlah keadaan terbatas"). Pada tahap ini, scanner akan membaca input karakter-ke-karakter, mengubah keadaannya sendiri berdasarkan karakter yang tengah dibaca. Setiap kondisi final (input dianggap valid) akan dicatat, bersama dengan lokasi input. Pada akhirnya scanner akan menemui keadaan penolakan, yang tidak akan berubah dengan input karakter apapun. Deteksi rekursi semacam ini akan mengakhiri proses pemindaian dan memindahkan keadaan scanner ke keadaan final terakhir, dan karenanya menyimpan informasi jenis dan besar <ref target="https://id.wikipedia.org/wiki/Leksem">leksem</ref> valid yang terpanjang di dalam input.</p>
<p>Namun lexeme tersebut belum punya nilai semantik apapun; pemberian nilai semantik pada setiap unit leksikal adalah tugas dari <hi rend="bold">evaluator</hi> yang memeriksa semua karakter setiap lexeme dan memberinya nilai tertentu. Saat sebuah lexeme telah memiliki informasi mengenai tipe dan nilainya, ia dapat secara valid disebut sebagai token.</p>
<p>Analisis leksikal membuat pekerjaan parser jadi lebih mudah; daripada membangun nama setiap fungsi dan variabel dari karakter-karakter yang menyusunnya, dengan analisis leksikal, parser cukup hanya berurusan dengan sekumpulan token dan nilai sintaksis masing-masing. Terlepas dari efisiensi pemrograman yang dapat dicapai dengan penggunaannya, proses kerja analisis leksikal yang membaca lebih dari sekali setiap karakter dari input yang diberikan menjadikan <hi rend="bold">penganalisis leksikal</hi> sebagai sub-sistem yang paling intensif melakukan komputasi, terutama bila digunakan dalam sebuah <ref target="https://id.wikipedia.org/wiki/Kompilator">kompilator</ref>.</p>
</text></body></html>